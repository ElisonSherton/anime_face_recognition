{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we shall be using Siamese Network in order to build a model to perform the task of face verification for a given character.\n",
    "\n",
    "The paper referred to for performing this experiment is [linked here](https://proceedings.neurips.cc/paper/1993/file/288cc0ff022877bd3df94bc9360b9c5d-Paper.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from siameseDataset import *\n",
    "from loss_func import *\n",
    "from siameseModel import *\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "import pandas as pd\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/vinayak/cleaned_anime_faces\"\n",
    "model_save_path = \"/home/vinayak/anime_face_recognition/enet_model.pth\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = {}\n",
    "split_info = pd.read_csv(f\"/home/vinayak/anime_face_recognition/data.csv\")\n",
    "partition[\"train\"] = list(split_info[split_info.label == \"train\"].images)\n",
    "random.shuffle(partition[\"train\"])\n",
    "partition[\"validation\"] = list(split_info[split_info.label == \"valid\"].images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://omoindrot.github.io/triplet-loss#strategies-in-online-mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training dataset and use it to create a training_generator\n",
    "training_set = siameseDataset(partition['train'])\n",
    "training_generator = torch.utils.data.DataLoader(training_set, batch_size = 1)\n",
    "# training_set.show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training dataset and use it to create a validation_generator\n",
    "validation_set = siameseDataset(partition['validation'], dtype = \"validation\")\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, batch_size = 1)\n",
    "# validation_set.show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and move it to appropriate device (i.e. cuda if gpu is available)\n",
    "model = enet_model().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function to be used for training\n",
    "loss_func = batchHardTripletLoss().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a learning rate and create an optimizer for training the model \n",
    "# (Adam with default momentum should be good)\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Define a learning rate scheduler so that you reduce the learning rate\n",
    "# As you progress across multiple epochs\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience = 3, factor = 0.2, threshold = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1   | Batch Number: 1   | Current Batch Loss: 2.20982| Average Train Loss: 2.20982\n",
      "Epoch: 1   | Batch Number: 30  | Current Batch Loss: 1.68284| Average Train Loss: 2.04862\n",
      "Epoch: 1   | Batch Number: 55  | Current Batch Loss: 1.27986| Average Train Loss: 1.79386\n",
      "_____________________________ End of Epoch 1 _____________________________\n",
      "Epoch: 1   | Train Loss: 1.79386| Valid Loss: 1.31989\n",
      "\n",
      "Epoch: 2   | Batch Number: 1   | Current Batch Loss: 1.34464| Average Train Loss: 1.34464\n",
      "Epoch: 2   | Batch Number: 30  | Current Batch Loss: 1.12947| Average Train Loss: 1.21264\n",
      "Epoch: 2   | Batch Number: 55  | Current Batch Loss: 1.06667| Average Train Loss: 1.15808\n",
      "_____________________________ End of Epoch 2 _____________________________\n",
      "Epoch: 2   | Train Loss: 1.15808| Valid Loss: 1.07646\n",
      "\n",
      "Epoch: 3   | Batch Number: 1   | Current Batch Loss: 1.0751 | Average Train Loss: 1.0751 \n",
      "Epoch: 3   | Batch Number: 30  | Current Batch Loss: 1.05491| Average Train Loss: 1.05316\n",
      "Epoch: 3   | Batch Number: 55  | Current Batch Loss: 1.01652| Average Train Loss: 1.04207\n",
      "_____________________________ End of Epoch 3 _____________________________\n",
      "Epoch: 3   | Train Loss: 1.04207| Valid Loss: 1.01691\n",
      "\n",
      "Epoch: 4   | Batch Number: 1   | Current Batch Loss: 1.01809| Average Train Loss: 1.01809\n",
      "Epoch: 4   | Batch Number: 30  | Current Batch Loss: 1.00683| Average Train Loss: 1.01724\n",
      "Epoch: 4   | Batch Number: 55  | Current Batch Loss: 1.00931| Average Train Loss: 1.01511\n",
      "_____________________________ End of Epoch 4 _____________________________\n",
      "Epoch: 4   | Train Loss: 1.01511| Valid Loss: 1.01369\n",
      "\n",
      "Epoch: 5   | Batch Number: 1   | Current Batch Loss: 1.01413| Average Train Loss: 1.01413\n",
      "Epoch: 5   | Batch Number: 30  | Current Batch Loss: 1.01186| Average Train Loss: 1.01211\n",
      "Epoch: 5   | Batch Number: 55  | Current Batch Loss: 1.00728| Average Train Loss: 1.01083\n",
      "_____________________________ End of Epoch 5 _____________________________\n",
      "Epoch: 5   | Train Loss: 1.01083| Valid Loss: 1.00766\n",
      "\n",
      "Epoch: 6   | Batch Number: 1   | Current Batch Loss: 1.00738| Average Train Loss: 1.00738\n",
      "Epoch: 6   | Batch Number: 30  | Current Batch Loss: 1.00868| Average Train Loss: 1.00936\n",
      "Epoch: 6   | Batch Number: 55  | Current Batch Loss: 1.00458| Average Train Loss: 1.00818\n",
      "_____________________________ End of Epoch 6 _____________________________\n",
      "Epoch: 6   | Train Loss: 1.00818| Valid Loss: 1.00587\n",
      "\n",
      "Epoch: 7   | Batch Number: 1   | Current Batch Loss: 1.00708| Average Train Loss: 1.00708\n",
      "Epoch: 7   | Batch Number: 30  | Current Batch Loss: 1.00499| Average Train Loss: 1.00674\n",
      "Epoch: 7   | Batch Number: 55  | Current Batch Loss: 1.00503| Average Train Loss: 1.00614\n",
      "_____________________________ End of Epoch 7 _____________________________\n",
      "Epoch: 7   | Train Loss: 1.00614| Valid Loss: 1.00439\n",
      "\n",
      "Epoch: 8   | Batch Number: 1   | Current Batch Loss: 1.00476| Average Train Loss: 1.00476\n",
      "Epoch: 8   | Batch Number: 30  | Current Batch Loss: 1.00339| Average Train Loss: 1.00439\n",
      "Epoch: 8   | Batch Number: 55  | Current Batch Loss: 1.00723| Average Train Loss: 1.00467\n",
      "_____________________________ End of Epoch 8 _____________________________\n",
      "Epoch: 8   | Train Loss: 1.00467| Valid Loss: 1.00436\n",
      "\n",
      "Epoch: 9   | Batch Number: 1   | Current Batch Loss: 1.00465| Average Train Loss: 1.00465\n",
      "Epoch: 9   | Batch Number: 30  | Current Batch Loss: 1.0049 | Average Train Loss: 1.00495\n",
      "Epoch: 9   | Batch Number: 55  | Current Batch Loss: 1.00408| Average Train Loss: 1.00464\n",
      "_____________________________ End of Epoch 9 _____________________________\n",
      "Epoch: 9   | Train Loss: 1.00464| Valid Loss: 1.00385\n",
      "\n",
      "Epoch: 10  | Batch Number: 1   | Current Batch Loss: 1.00356| Average Train Loss: 1.00356\n",
      "Epoch: 10  | Batch Number: 30  | Current Batch Loss: 1.00193| Average Train Loss: 1.00443\n",
      "Epoch: 10  | Batch Number: 55  | Current Batch Loss: 1.00452| Average Train Loss: 1.0041 \n",
      "_____________________________ End of Epoch 10 _____________________________\n",
      "Epoch: 10  | Train Loss: 1.0041 | Valid Loss: 1.00319\n",
      "\n",
      "Epoch: 11  | Batch Number: 1   | Current Batch Loss: 1.0036 | Average Train Loss: 1.0036 \n",
      "Epoch: 11  | Batch Number: 30  | Current Batch Loss: 1.00379| Average Train Loss: 1.00334\n",
      "Epoch: 11  | Batch Number: 55  | Current Batch Loss: 1.00438| Average Train Loss: 1.00343\n",
      "_____________________________ End of Epoch 11 _____________________________\n",
      "Epoch: 11  | Train Loss: 1.00343| Valid Loss: 1.00266\n",
      "\n",
      "Epoch: 12  | Batch Number: 1   | Current Batch Loss: 1.00265| Average Train Loss: 1.00265\n",
      "Epoch: 12  | Batch Number: 30  | Current Batch Loss: 1.00322| Average Train Loss: 1.00316\n",
      "Epoch: 12  | Batch Number: 55  | Current Batch Loss: 1.00308| Average Train Loss: 1.0031 \n",
      "_____________________________ End of Epoch 12 _____________________________\n",
      "Epoch: 12  | Train Loss: 1.0031 | Valid Loss: 1.00268\n",
      "\n",
      "Epoch: 13  | Batch Number: 1   | Current Batch Loss: 1.00328| Average Train Loss: 1.00328\n",
      "Epoch: 13  | Batch Number: 30  | Current Batch Loss: 1.00216| Average Train Loss: 1.00301\n",
      "Epoch: 13  | Batch Number: 55  | Current Batch Loss: 1.00419| Average Train Loss: 1.00297\n",
      "_____________________________ End of Epoch 13 _____________________________\n",
      "Epoch: 13  | Train Loss: 1.00297| Valid Loss: 1.0028 \n",
      "\n",
      "Epoch: 14  | Batch Number: 1   | Current Batch Loss: 1.00239| Average Train Loss: 1.00239\n",
      "Epoch: 14  | Batch Number: 30  | Current Batch Loss: 1.00368| Average Train Loss: 1.00318\n",
      "Epoch: 14  | Batch Number: 55  | Current Batch Loss: 1.00363| Average Train Loss: 1.00319\n",
      "_____________________________ End of Epoch 14 _____________________________\n",
      "Epoch: 14  | Train Loss: 1.00319| Valid Loss: 1.0028 \n",
      "\n",
      "Epoch: 15  | Batch Number: 1   | Current Batch Loss: 1.00223| Average Train Loss: 1.00223\n",
      "Epoch: 15  | Batch Number: 30  | Current Batch Loss: 1.00393| Average Train Loss: 1.00301\n",
      "Epoch: 15  | Batch Number: 55  | Current Batch Loss: 1.00318| Average Train Loss: 1.00295\n",
      "_____________________________ End of Epoch 15 _____________________________\n",
      "Epoch: 15  | Train Loss: 1.00295| Valid Loss: 1.00264\n",
      "\n",
      "Epoch: 16  | Batch Number: 1   | Current Batch Loss: 1.00316| Average Train Loss: 1.00316\n",
      "Epoch: 16  | Batch Number: 30  | Current Batch Loss: 1.00338| Average Train Loss: 1.0029 \n",
      "Epoch: 16  | Batch Number: 55  | Current Batch Loss: 1.00374| Average Train Loss: 1.00288\n",
      "_____________________________ End of Epoch 16 _____________________________\n",
      "Epoch: 16  | Train Loss: 1.00288| Valid Loss: 1.00269\n",
      "\n",
      "Epoch: 17  | Batch Number: 1   | Current Batch Loss: 1.00296| Average Train Loss: 1.00296\n",
      "Epoch: 17  | Batch Number: 30  | Current Batch Loss: 1.00343| Average Train Loss: 1.00289\n",
      "Epoch: 17  | Batch Number: 55  | Current Batch Loss: 1.00321| Average Train Loss: 1.00291\n",
      "_____________________________ End of Epoch 17 _____________________________\n",
      "Epoch: 17  | Train Loss: 1.00291| Valid Loss: 1.00292\n",
      "\n",
      "Epoch: 18  | Batch Number: 1   | Current Batch Loss: 1.00312| Average Train Loss: 1.00312\n",
      "Epoch: 18  | Batch Number: 30  | Current Batch Loss: 1.00246| Average Train Loss: 1.00271\n",
      "Epoch: 18  | Batch Number: 55  | Current Batch Loss: 1.00243| Average Train Loss: 1.00272\n",
      "_____________________________ End of Epoch 18 _____________________________\n",
      "Epoch: 18  | Train Loss: 1.00272| Valid Loss: 1.0031 \n",
      "\n",
      "Epoch: 19  | Batch Number: 1   | Current Batch Loss: 1.00269| Average Train Loss: 1.00269\n",
      "Epoch: 19  | Batch Number: 30  | Current Batch Loss: 1.00355| Average Train Loss: 1.00264\n",
      "Epoch: 19  | Batch Number: 55  | Current Batch Loss: 1.00267| Average Train Loss: 1.00264\n",
      "_____________________________ End of Epoch 19 _____________________________\n",
      "Epoch: 19  | Train Loss: 1.00264| Valid Loss: 1.00279\n",
      "\n",
      "Epoch: 20  | Batch Number: 1   | Current Batch Loss: 1.00147| Average Train Loss: 1.00147\n",
      "Epoch: 20  | Batch Number: 30  | Current Batch Loss: 1.00235| Average Train Loss: 1.00281\n",
      "Epoch: 20  | Batch Number: 55  | Current Batch Loss: 1.00248| Average Train Loss: 1.00274\n",
      "_____________________________ End of Epoch 20 _____________________________\n",
      "Epoch: 20  | Train Loss: 1.00274| Valid Loss: 1.00264\n",
      "\n",
      "Epoch: 21  | Batch Number: 1   | Current Batch Loss: 1.00233| Average Train Loss: 1.00233\n",
      "Epoch: 21  | Batch Number: 30  | Current Batch Loss: 1.00289| Average Train Loss: 1.00263\n",
      "Epoch: 21  | Batch Number: 55  | Current Batch Loss: 1.002  | Average Train Loss: 1.00262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________ End of Epoch 21 _____________________________\n",
      "Epoch: 21  | Train Loss: 1.00262| Valid Loss: 1.00286\n",
      "\n",
      "Epoch: 22  | Batch Number: 1   | Current Batch Loss: 1.00251| Average Train Loss: 1.00251\n",
      "Epoch: 22  | Batch Number: 30  | Current Batch Loss: 1.00259| Average Train Loss: 1.00267\n",
      "Epoch: 22  | Batch Number: 55  | Current Batch Loss: 1.00225| Average Train Loss: 1.00258\n",
      "_____________________________ End of Epoch 22 _____________________________\n",
      "Epoch: 22  | Train Loss: 1.00258| Valid Loss: 1.00235\n",
      "\n",
      "Epoch: 23  | Batch Number: 1   | Current Batch Loss: 1.00272| Average Train Loss: 1.00272\n",
      "Epoch: 23  | Batch Number: 30  | Current Batch Loss: 1.00325| Average Train Loss: 1.00227\n",
      "Epoch: 23  | Batch Number: 55  | Current Batch Loss: 1.00154| Average Train Loss: 1.00232\n",
      "_____________________________ End of Epoch 23 _____________________________\n",
      "Epoch: 23  | Train Loss: 1.00232| Valid Loss: 1.0026 \n",
      "\n",
      "Epoch: 24  | Batch Number: 1   | Current Batch Loss: 1.00254| Average Train Loss: 1.00254\n",
      "Epoch: 24  | Batch Number: 30  | Current Batch Loss: 1.00145| Average Train Loss: 1.00236\n",
      "Epoch: 24  | Batch Number: 55  | Current Batch Loss: 1.00188| Average Train Loss: 1.00228\n",
      "_____________________________ End of Epoch 24 _____________________________\n",
      "Epoch: 24  | Train Loss: 1.00228| Valid Loss: 1.00242\n",
      "\n",
      "Epoch: 25  | Batch Number: 1   | Current Batch Loss: 1.00251| Average Train Loss: 1.00251\n",
      "Epoch: 25  | Batch Number: 30  | Current Batch Loss: 1.00249| Average Train Loss: 1.00228\n",
      "Epoch: 25  | Batch Number: 55  | Current Batch Loss: 1.00215| Average Train Loss: 1.0023 \n",
      "_____________________________ End of Epoch 25 _____________________________\n",
      "Epoch: 25  | Train Loss: 1.0023 | Valid Loss: 1.00226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "n_epochs = 25\n",
    "n_train_batches = len(training_generator)\n",
    "n_valid_batches = len(validation_generator)\n",
    "PRINT_PROGRESS = 30\n",
    "\n",
    "round_off = lambda x: round(x, 5)\n",
    "\n",
    "# Loop over number of epochs\n",
    "for epch in range(n_epochs):\n",
    "    \n",
    "    # Initialize the loss values to zero at the beginning of the epoch\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "\n",
    "    # Train for an epoch\n",
    "    for idx, (images, labels) in enumerate(training_generator, start = 1):\n",
    "        images, labels = images[0].to(DEVICE), labels.to(DEVICE)\n",
    "        feature_vectors = model(images)\n",
    "        loss = loss_func(feature_vectors, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = round_off(loss.item())\n",
    "        train_loss += batch_loss\n",
    "        \n",
    "        if (idx % PRINT_PROGRESS == 0) or (idx == 1) or (idx == n_train_batches):\n",
    "            print(f\"Epoch: {(epch + 1):<4}| Batch Number: {idx:<4}| Current Batch Loss: {batch_loss:<7}| Average Train Loss: {round_off(train_loss / idx):<7}\")\n",
    "    \n",
    "    # Validate after the trained epoch\n",
    "    for images, labels in validation_generator:\n",
    "        images, labels = images[0].to(DEVICE), labels.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            feature_vectors = model(images)\n",
    "            loss = loss_func(feature_vectors, labels)\n",
    "            valid_loss += round_off(loss.item())\n",
    "    \n",
    "    # Average the train and valid losses across all batches and save it to our array\n",
    "    train_loss = round_off(train_loss / n_train_batches)\n",
    "    valid_loss = round_off(valid_loss / n_valid_batches)\n",
    "    \n",
    "    print(f\"_____________________________ End of Epoch {epch + 1} _____________________________\")\n",
    "    print(f\"Epoch: {(epch + 1):<4}| Train Loss: {train_loss:<7}| Valid Loss: {valid_loss:<7}\")\n",
    "    print()\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    # Check the valid loss and reduce learning rate as per the need\n",
    "    scheduler.step(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the losses to a loss_history.csv file on the disk\n",
    "history = pd.DataFrame({\"train_loss\": train_losses, \"valid_loss\":valid_losses})\n",
    "history.to_csv(\"loss_history.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to our disk\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
