{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we shall be using Siamese Network in order to build a model to perform the task of face verification for a given character.\n",
    "\n",
    "The paper referred to for performing this experiment is [linked here](https://proceedings.neurips.cc/paper/1993/file/288cc0ff022877bd3df94bc9360b9c5d-Paper.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from siameseDataset import *\n",
    "from loss_func import *\n",
    "from siameseModel import *\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "import pandas as pd\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/vinayak/AnimeFaceDset\"\n",
    "model_save_path = \"/home/vinayak/anime_face_recognition/resources/enet_model.pth\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = {}\n",
    "split_info = pd.read_csv(f\"/home/vinayak/anime_face_recognition/resources/data.csv\")\n",
    "partition[\"train\"] = list(split_info[split_info.label == \"train\"].images)\n",
    "random.shuffle(partition[\"train\"])\n",
    "partition[\"validation\"] = list(split_info[split_info.label == \"valid\"].images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://omoindrot.github.io/triplet-loss#strategies-in-online-mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training dataset and use it to create a training_generator\n",
    "training_set = siameseDataset(partition['train'])\n",
    "training_generator = torch.utils.data.DataLoader(training_set, batch_size = 1)\n",
    "# training_set.show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training dataset and use it to create a validation_generator\n",
    "validation_set = siameseDataset(partition['validation'], dtype = \"validation\")\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, batch_size = 1)\n",
    "# validation_set.show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and move it to appropriate device (i.e. cuda if gpu is available)\n",
    "model = enet_model().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function to be used for training\n",
    "loss_func = batchHardTripletLoss(margin = 0.15).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a learning rate and create an optimizer for training the model \n",
    "# (Adam with default momentum should be good)\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Define a learning rate scheduler so that you reduce the learning rate\n",
    "# As you progress across multiple epochs\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 3, gamma = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1   \n",
      "Batch Number: 1 | Current Batch Loss: 1.5385 | Average Train Loss: 1.5385 \n",
      "Batch Number: 30| Current Batch Loss: 1.04631| Average Train Loss: 1.09829\n",
      "Batch Number: 60| Current Batch Loss: 0.52496| Average Train Loss: 0.90696\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 1  --->  Train Loss: 0.90696  --->  Valid Loss: 0.51021\n",
      "\n",
      "Epoch 2   \n",
      "Batch Number: 1 | Current Batch Loss: 0.60355| Average Train Loss: 0.60355\n",
      "Batch Number: 30| Current Batch Loss: 0.11913| Average Train Loss: 0.34642\n",
      "Batch Number: 60| Current Batch Loss: 0.47944| Average Train Loss: 0.33855\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 2  --->  Train Loss: 0.33855  --->  Valid Loss: 0.29299\n",
      "\n",
      "Epoch 3   \n",
      "Batch Number: 1 | Current Batch Loss: 0.32733| Average Train Loss: 0.32733\n",
      "Batch Number: 30| Current Batch Loss: 0.18117| Average Train Loss: 0.19866\n",
      "Batch Number: 60| Current Batch Loss: 0.55078| Average Train Loss: 0.20224\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 3  --->  Train Loss: 0.20224  --->  Valid Loss: 0.2394 \n",
      "\n",
      "Epoch 4   \n",
      "Batch Number: 1 | Current Batch Loss: 0.1755 | Average Train Loss: 0.1755 \n",
      "Batch Number: 30| Current Batch Loss: 0.08786| Average Train Loss: 0.17078\n",
      "Batch Number: 60| Current Batch Loss: 0.16673| Average Train Loss: 0.1538 \n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 4  --->  Train Loss: 0.1538   --->  Valid Loss: 0.16645\n",
      "\n",
      "Epoch 5   \n",
      "Batch Number: 1 | Current Batch Loss: 0.27445| Average Train Loss: 0.27445\n",
      "Batch Number: 30| Current Batch Loss: 0.17537| Average Train Loss: 0.15532\n",
      "Batch Number: 60| Current Batch Loss: 0.10443| Average Train Loss: 0.15074\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 5  --->  Train Loss: 0.15074  --->  Valid Loss: 0.18426\n",
      "\n",
      "Epoch 6   \n",
      "Batch Number: 1 | Current Batch Loss: 0.0585 | Average Train Loss: 0.0585 \n",
      "Batch Number: 30| Current Batch Loss: 0.15256| Average Train Loss: 0.12077\n",
      "Batch Number: 60| Current Batch Loss: 0.51501| Average Train Loss: 0.12305\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 6  --->  Train Loss: 0.12305  --->  Valid Loss: 0.15046\n",
      "\n",
      "Epoch 7   \n",
      "Batch Number: 1 | Current Batch Loss: 0.06105| Average Train Loss: 0.06105\n",
      "Batch Number: 30| Current Batch Loss: 0.27345| Average Train Loss: 0.13583\n",
      "Batch Number: 60| Current Batch Loss: 0.08867| Average Train Loss: 0.11768\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 7  --->  Train Loss: 0.11768  --->  Valid Loss: 0.14943\n",
      "\n",
      "Epoch 8   \n",
      "Batch Number: 1 | Current Batch Loss: 0.1082 | Average Train Loss: 0.1082 \n",
      "Batch Number: 30| Current Batch Loss: 0.0526 | Average Train Loss: 0.0864 \n",
      "Batch Number: 60| Current Batch Loss: 0.21286| Average Train Loss: 0.0973 \n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 8  --->  Train Loss: 0.0973   --->  Valid Loss: 0.19392\n",
      "\n",
      "Epoch 9   \n",
      "Batch Number: 1 | Current Batch Loss: 0.10378| Average Train Loss: 0.10378\n",
      "Batch Number: 30| Current Batch Loss: 0.13686| Average Train Loss: 0.07786\n",
      "Batch Number: 60| Current Batch Loss: 0.43082| Average Train Loss: 0.10233\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 9  --->  Train Loss: 0.10233  --->  Valid Loss: 0.16431\n",
      "\n",
      "Epoch 10  \n",
      "Batch Number: 1 | Current Batch Loss: 0.20106| Average Train Loss: 0.20106\n",
      "Batch Number: 30| Current Batch Loss: 0.05145| Average Train Loss: 0.06318\n",
      "Batch Number: 60| Current Batch Loss: 0.09351| Average Train Loss: 0.06919\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 10 --->  Train Loss: 0.06919  --->  Valid Loss: 0.18541\n",
      "\n",
      "Epoch 11  \n",
      "Batch Number: 1 | Current Batch Loss: 0.04145| Average Train Loss: 0.04145\n",
      "Batch Number: 30| Current Batch Loss: 0.04746| Average Train Loss: 0.0517 \n",
      "Batch Number: 60| Current Batch Loss: 0.01335| Average Train Loss: 0.07846\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 11 --->  Train Loss: 0.07846  --->  Valid Loss: 0.15675\n",
      "\n",
      "Epoch 12  \n",
      "Batch Number: 1 | Current Batch Loss: 0.0231 | Average Train Loss: 0.0231 \n",
      "Batch Number: 30| Current Batch Loss: 0.0    | Average Train Loss: 0.0716 \n",
      "Batch Number: 60| Current Batch Loss: 0.1499 | Average Train Loss: 0.07627\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 12 --->  Train Loss: 0.07627  --->  Valid Loss: 0.13363\n",
      "\n",
      "Epoch 13  \n",
      "Batch Number: 1 | Current Batch Loss: 0.01651| Average Train Loss: 0.01651\n",
      "Batch Number: 30| Current Batch Loss: 0.07115| Average Train Loss: 0.06891\n",
      "Batch Number: 60| Current Batch Loss: 0.03589| Average Train Loss: 0.07096\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 13 --->  Train Loss: 0.07096  --->  Valid Loss: 0.16417\n",
      "\n",
      "Epoch 14  \n",
      "Batch Number: 1 | Current Batch Loss: 0.082  | Average Train Loss: 0.082  \n",
      "Batch Number: 30| Current Batch Loss: 0.00907| Average Train Loss: 0.05082\n",
      "Batch Number: 60| Current Batch Loss: 0.02649| Average Train Loss: 0.05461\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 14 --->  Train Loss: 0.05461  --->  Valid Loss: 0.15114\n",
      "\n",
      "Epoch 15  \n",
      "Batch Number: 1 | Current Batch Loss: 0.0491 | Average Train Loss: 0.0491 \n",
      "Batch Number: 30| Current Batch Loss: 0.0225 | Average Train Loss: 0.04721\n",
      "Batch Number: 60| Current Batch Loss: 0.09385| Average Train Loss: 0.04195\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 15 --->  Train Loss: 0.04195  --->  Valid Loss: 0.13094\n",
      "\n",
      "Epoch 16  \n",
      "Batch Number: 1 | Current Batch Loss: 0.0    | Average Train Loss: 0.0    \n",
      "Batch Number: 30| Current Batch Loss: 0.03628| Average Train Loss: 0.0528 \n",
      "Batch Number: 60| Current Batch Loss: 0.0    | Average Train Loss: 0.05038\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 16 --->  Train Loss: 0.05038  --->  Valid Loss: 0.12088\n",
      "\n",
      "Epoch 17  \n",
      "Batch Number: 1 | Current Batch Loss: 0.01469| Average Train Loss: 0.01469\n",
      "Batch Number: 30| Current Batch Loss: 0.13278| Average Train Loss: 0.046  \n",
      "Batch Number: 60| Current Batch Loss: 0.0    | Average Train Loss: 0.04986\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 17 --->  Train Loss: 0.04986  --->  Valid Loss: 0.11881\n",
      "\n",
      "Epoch 18  \n",
      "Batch Number: 1 | Current Batch Loss: 0.0957 | Average Train Loss: 0.0957 \n",
      "Batch Number: 30| Current Batch Loss: 0.04011| Average Train Loss: 0.07242\n",
      "Batch Number: 60| Current Batch Loss: 0.0    | Average Train Loss: 0.05706\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 18 --->  Train Loss: 0.05706  --->  Valid Loss: 0.14488\n",
      "\n",
      "Epoch 19  \n",
      "Batch Number: 1 | Current Batch Loss: 0.01735| Average Train Loss: 0.01735\n",
      "Batch Number: 30| Current Batch Loss: 0.00114| Average Train Loss: 0.03583\n",
      "Batch Number: 60| Current Batch Loss: 0.0    | Average Train Loss: 0.0412 \n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 19 --->  Train Loss: 0.0412   --->  Valid Loss: 0.15702\n",
      "\n",
      "Epoch 20  \n",
      "Batch Number: 1 | Current Batch Loss: 0.00522| Average Train Loss: 0.00522\n",
      "Batch Number: 30| Current Batch Loss: 0.13773| Average Train Loss: 0.04238\n",
      "Batch Number: 60| Current Batch Loss: 0.01455| Average Train Loss: 0.03602\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 20 --->  Train Loss: 0.03602  --->  Valid Loss: 0.12519\n",
      "\n",
      "Epoch 21  \n",
      "Batch Number: 1 | Current Batch Loss: 0.0    | Average Train Loss: 0.0    \n",
      "Batch Number: 30| Current Batch Loss: 0.00023| Average Train Loss: 0.0559 \n",
      "Batch Number: 60| Current Batch Loss: 0.12147| Average Train Loss: 0.04728\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 21 --->  Train Loss: 0.04728  --->  Valid Loss: 0.11055\n",
      "\n",
      "Epoch 22  \n",
      "Batch Number: 1 | Current Batch Loss: 0.0    | Average Train Loss: 0.0    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number: 30| Current Batch Loss: 0.0    | Average Train Loss: 0.04296\n",
      "Batch Number: 60| Current Batch Loss: 0.19021| Average Train Loss: 0.04378\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 22 --->  Train Loss: 0.04378  --->  Valid Loss: 0.10771\n",
      "\n",
      "Epoch 23  \n",
      "Batch Number: 1 | Current Batch Loss: 0.01068| Average Train Loss: 0.01068\n",
      "Batch Number: 30| Current Batch Loss: 0.0156 | Average Train Loss: 0.02127\n",
      "Batch Number: 60| Current Batch Loss: 0.02132| Average Train Loss: 0.03429\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 23 --->  Train Loss: 0.03429  --->  Valid Loss: 0.10416\n",
      "\n",
      "Epoch 24  \n",
      "Batch Number: 1 | Current Batch Loss: 0.0    | Average Train Loss: 0.0    \n",
      "Batch Number: 30| Current Batch Loss: 0.09312| Average Train Loss: 0.04021\n",
      "Batch Number: 60| Current Batch Loss: 0.08569| Average Train Loss: 0.03705\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 24 --->  Train Loss: 0.03705  --->  Valid Loss: 0.15325\n",
      "\n",
      "Epoch 25  \n",
      "Batch Number: 1 | Current Batch Loss: 0.02208| Average Train Loss: 0.02208\n",
      "Batch Number: 30| Current Batch Loss: 0.14067| Average Train Loss: 0.03731\n",
      "Batch Number: 60| Current Batch Loss: 0.03714| Average Train Loss: 0.03348\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 25 --->  Train Loss: 0.03348  --->  Valid Loss: 0.11367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "n_epochs = 25\n",
    "n_train_batches = len(training_generator)\n",
    "n_valid_batches = len(validation_generator)\n",
    "PRINT_PROGRESS = 30\n",
    "\n",
    "round_off = lambda x: round(x, 5)\n",
    "\n",
    "# Loop over number of epochs\n",
    "for epch in range(n_epochs):\n",
    "    \n",
    "    print(f\"Epoch {(epch + 1):<4}\")\n",
    "    # Initialize the loss values to zero at the beginning of the epoch\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "\n",
    "    # Train for an epoch\n",
    "    for idx, (images, labels) in enumerate(training_generator, start = 1):\n",
    "        images, labels = images[0].to(DEVICE), labels.to(DEVICE)\n",
    "        feature_vectors = model(images)\n",
    "        loss = loss_func(feature_vectors, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = round_off(loss.item())\n",
    "        train_loss += batch_loss\n",
    "        \n",
    "        if (idx % PRINT_PROGRESS == 0) or (idx == 1) or (idx == n_train_batches):\n",
    "            print(f\"Batch Number: {idx:<2}| Current Batch Loss: {batch_loss:<7}| Average Train Loss: {round_off(train_loss / idx):<7}\")\n",
    "    \n",
    "    # Validate after the trained epoch\n",
    "    for images, labels in validation_generator:\n",
    "        images, labels = images[0].to(DEVICE), labels.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            feature_vectors = model(images)\n",
    "            loss = loss_func(feature_vectors, labels)\n",
    "            valid_loss += round_off(loss.item())\n",
    "    \n",
    "    # Reset the states of training and validation sets\n",
    "    validation_set.characters_selected = {k:0 for k in validation_set.classes}\n",
    "    validation_set.images_selected = {k:False for k in validation_set.images}\n",
    "    \n",
    "    training_set.characters_selected = {k:0 for k in training_set.classes}\n",
    "    training_set.images_selected = {k:False for k in training_set.images}\n",
    "    \n",
    "    # Average the train and valid losses across all batches and save it to our array\n",
    "    train_loss = round_off(train_loss / n_train_batches)\n",
    "    valid_loss = round_off(valid_loss / n_valid_batches)\n",
    "    \n",
    "    print(\"\".join([\"-\"]*75))\n",
    "    print(f\"Summary for Epoch {(epch + 1):<2} --->  Train Loss: {train_loss:<7}  --->  Valid Loss: {valid_loss:<7}\")\n",
    "    print()\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    # Check the valid loss and reduce learning rate as per the need\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the losses to a loss_history.csv file on the disk\n",
    "history = pd.DataFrame({\"train_loss\": train_losses, \"valid_loss\":valid_losses})\n",
    "history.to_csv(\"loss_history.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve obtained when training\n",
    "ax = history.plot();\n",
    "ax.set_xlabel(\"Epoch Number\")\n",
    "ax.set_ylabel(\"Batch Hard Triplet Loss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to our disk\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_size': 3,\n",
       " 'gamma': 0.8,\n",
       " 'base_lrs': [0.0001],\n",
       " 'last_epoch': 25,\n",
       " '_step_count': 26,\n",
       " '_get_lr_called_within_step': False,\n",
       " '_last_lr': [1.677721600000001e-05]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the progresion of learning rates\n",
    "scheduler.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
