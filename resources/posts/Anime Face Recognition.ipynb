{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lesser-hunter",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "I have had been meaning to study an area of deep learning called metric learning for a while now and I figured out a great learning use-case which piqued my interest and made me delve straight into it. It's the **face recognition problem**.\n",
    "\n",
    "But wait, there's a slight twist here. We're not doing plain human facial recognition because it's just *meh, very commonplace!*. As a proponent of the otaku culture, I thought let's do facial recognition with anime characters!!\n",
    "\n",
    "![](https://pbs.twimg.com/media/En2zrWXXIAE_RiD.jpg)\n",
    "\n",
    "In this post, we will cover everything - right from understanding the problem statement & curating our own dataset to building a face recognition model and telling characters apart from each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stupid-cologne",
   "metadata": {},
   "source": [
    "## But what is Metric Learning?\n",
    "\n",
    "Many Machine Learning problems usually fall under two buckets \n",
    "\n",
    "- Classification - Where given a set of features (X), we need to produce a discrete output (y). eg. Telling if a given image is of a cat or a dog.\n",
    "- Regression - Where given a set of features (X), we need to produce a continuous output (y). eg. Given the demographic information of people, predict how much money they make.\n",
    "\n",
    "Although these two are some of the most common usecases, there's other usecases one of which is called the retrieval task. \n",
    "\n",
    "In this task, given a datapoint, we are supposed to find out other datapoints which are close to or away from this datapoint in some rigidly defined way. *Face-identification, recommendation systems etc. are the class of problems which commonly come under the umbrella of this task.*\n",
    "\n",
    "Here an approach called similarity learning/ metric learning proves to be useful.\n",
    "\n",
    "Wikipedia defines it as\n",
    "\n",
    "> Metric learning is the task of learning a distance function over objects.\n",
    "\n",
    "It could also loosely be referred to as Similarity learning since the distance function could be used to rank objects from most similar to least similar or vice versa based on the end application. Here, using deep learning, a distance/similarity function like the Euclidean distance or Manhattan distance or even cosine similarity are used in the loss function to determine the extent to which two or more images are similar/different from one another.\n",
    "\n",
    "In our problem of anime face identification, we will be using a loss function called Triplet Loss function and modifying it [as mentioned in this paper](https://arxiv.org/abs/1703.07737)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-excuse",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "Now, there's no particular prescription here since this is a free-flow project, so I selected some characters from a few anime which I particularly like. \n",
    "\n",
    "I have selected 40 characters' and per character, we will have around 32 images making it a 1280 images dataset in it's entirety. A character sprite (post collection) for all these characters can be seen below. I have meticuluously crafted this dataset to include images which include characters having some faces very similar to each other (eg. Natsume Takashi & Natori Shuiichi, Tomoya Aki & Arima Kousei etc.) to see how good a system we can build for telling people apart from one other.\n",
    "\n",
    "<img src=\"../img/anime_faces_2.png\" style=\"border:1px solid black\">\n",
    "\n",
    "A list of all the characters along with the anime they belong to are given below\n",
    "\n",
    "<img src=\"../img/characters.png\" style=\"border:1px solid black\">\n",
    "\n",
    "Now that we have our characters and estimate figured out, let's step into actually getting the data from the web.\n",
    "\n",
    "> Quality Data is the backbone of any predictive model. No model/algorithm can protect you from the perils of biases & other issues induced by compromised data. Collect your data wisely!\n",
    "\n",
    "There are many search engines and sites from where we can manually download the data (only for purposes of training the model and not for resharing, redistribution, modification & resharing etc.) but that would take hours on end; it's not an efficient process for data collection. Here's where web-scrapers which are programs that crawl the web and scrape the data in an automated fashion could come in very handy. It is a very involved process and out of the scope of this post; For this post, we shall look at another popular package called `google_images_download` which could be used to scrape google images and save them locally.\n",
    "\n",
    "\n",
    "## Installation\n",
    "\n",
    "You can simply pip install this library as it's available on python package index (PyPI).\n",
    "\n",
    "In your terminal/powershell/command prompt, create a virtual environment (optional, I have observed keeping environments separate can really help save potential dependency clashes in the future), and install the library as follows:\n",
    "\n",
    "``` python\n",
    "# https://pypi.org/project/google_images_download/\n",
    "pip install google_images_download\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-ivory",
   "metadata": {},
   "source": [
    "## Downloading Images\n",
    "\n",
    "This library is really easy to use and [well documented here](https://google-images-download.readthedocs.io/en/latest/index.html). It provides a commandline option to download images as well as a script option where we can write our own python code and customize the downloads to happen in a particular manner.\n",
    "\n",
    "We will use the script option to download the images for now. The script looks as follows\n",
    "\n",
    "```python\n",
    "\n",
    "# Import required libraries\n",
    "from google_images_download import google_images_download   \n",
    "\n",
    "OUT_DIR = \"./images\"\n",
    "\n",
    "# Instantiate the class for downloading images\n",
    "response = google_images_download.googleimagesdownload()   \n",
    "\n",
    "def download_images(keyword, limit = 1):\n",
    "    \"\"\"\n",
    "    Given the keyword that we're looking for and a limit on max number of images to be downloaded,\n",
    "    downloads the image and places them in a folder in downloads repo in the current directory structure.\n",
    "    \"\"\"\n",
    "    #creating list of arguments\n",
    "    arguments = {\"keywords\": keyword ,\n",
    "                 \"limit\": limit , \n",
    "                 \"print_urls\": False,\n",
    "                 \"output_directory\": OUT_DIR}   \n",
    "\n",
    "    # Pass the arguments to above function and download images\n",
    "    paths = response.download(arguments)  \n",
    "```\n",
    "\n",
    "There's primarily only two steps to download the images.\n",
    "\n",
    "1. Instantiate an object of googleimagesdownload class.\n",
    "2. Define the arguments for downloading data. There's many arguments that you can pass to customize your download process; some of them are\n",
    "\n",
    "    - keywords: The keywords which need to be looked for when doing a google image search.\n",
    "    - limit: How many images need to be downloaded\n",
    "    - print_urls: Whether to print the url of the downloaded image inline after every image download\n",
    "    - output_directory: Where to store the images to\n",
    "    \n",
    "    Of these, only keywords and limit are mandatory, all others are optional. In case of no directory specified, the script creates a download folder in the same location as the directory from which the script is run and within it, a folder with the keywords name and stores the downloaded images therein.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-better",
   "metadata": {},
   "source": [
    "## Some troubleshooting tips while using this library\n",
    "\n",
    "A couple of handful tips when using this library are as follows:\n",
    "\n",
    "1. If you are downloading more than 99 images, this script mode will not work. You will have to use the CLI to download images and download an appropriate web driver for scraping the images. You look at the version of your browser (Chrome) and from the official site, download the webdriver for the browser for that respective version and provide a path to through the CLI\n",
    "\n",
    "```python\n",
    "googleimagesdownload --keywords \"INSERT KEYWORD HERE\" --limit NUMBER_OF_IMAGES --chromedriver PATH_TO_CHROMEDRIVER\n",
    "```\n",
    "\n",
    "For more info, [look here](https://google-images-download.readthedocs.io/en/latest/troubleshooting.html#installing-the-chromedriver-with-selenium). \n",
    "\n",
    "2. Sometimes, you might need to download another dependency of `webdriver_manager` in order to get this library to work. This can be achieved by a simple pip install as follows.\n",
    "\n",
    "```python\n",
    "pip install webdriver_manager\n",
    "```\n",
    "\n",
    "For more troubleshooting options, you can [refer this website](https://google-images-download.readthedocs.io/en/latest/troubleshooting.html#installing-the-chromedriver-with-selenium)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-diameter",
   "metadata": {},
   "source": [
    "## Preprocessing the images\n",
    "\n",
    "Since we want to build a face recognition system, we are more interested in faces as against the entire character's body. So, we would like to crop the entire image down to only include the faces of our characters. This is a crucial step because the models that we'll build successively massively depend on the way we curate our data now. \n",
    "\n",
    "There's several different ways to do this, of which we'll discuss two primarily. One is the usage of LBP Cascades to build a face detection system; in the initial days (pre-DL days), this or HAAR Cascades were widely adopted standards especially in our mobile phones and such. \n",
    "\n",
    "[Nagadomi](https://github.com/nagadomi) has built an lbp cascade which many people have used in their projects and it is also known to work well in many cases. Let's use it to crop our images and gauge it's performance.\n",
    "\n",
    "## Installation\n",
    "\n",
    "The repo is hosted on github and is available for use by one and all. Let's get the codebase from there first.\n",
    "\n",
    "Clone this repository or download the code as zip [from here](https://github.com/nagadomi/lbpcascade_animeface). After you cloned the repo/ or unzipped the contents of the repo, navigate to the folder and open a terminal/command prompt/powershell from this location. Next run the following command to get the xml file which hold the parameters needed for inference from the LBP Cascade.\n",
    "\n",
    "```\n",
    "wget https://raw.githubusercontent.com/nagadomi/lbpcascade_animeface/master/lbpcascade_animeface.xml\n",
    "```\n",
    "\n",
    "Next, install opencv library to your environment if you don't have it installed. It could also be fetched from pypi with a simple pip install\n",
    "\n",
    "```\n",
    "pip install opencv-python\n",
    "```\n",
    "\n",
    "Now you're ready to use nagadomi's facial extraction cascade as follows.\n",
    "\n",
    "```python\n",
    "# To use LBP Cascade for face detection\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Specify the source and destination paths\n",
    "src_path = \"/home/vinayak/random_anime_faces\"\n",
    "dest_path = \"/home/vinayak/cropped_images\"\n",
    "\n",
    "# Use the cascade xml file to create a haar cascade detector\n",
    "cascade = cv2.CascadeClassifier(\"../resources/lbpcascade_animeface.xml\")\n",
    "\n",
    "# Detect faces from a given image file and store the face croppings to the output folder\n",
    "def detect(file, output_folder):\n",
    "    try:\n",
    "        # Read the image and convert it to single channel\n",
    "        filename = file.split(\"/\")[-1]\n",
    "        image = cv2.imread(file, cv2.IMREAD_COLOR)\n",
    "        gray = cv2.equalizeHist(cv2.cvtColor(image, cv2.COLOR_BGR2GRAY))\n",
    "        \n",
    "        # Run the detector and identify patches of faces\n",
    "        faces = cascade.detectMultiScale(gray,\n",
    "                                        # detector options\n",
    "                                        scaleFactor = 1.1,\n",
    "                                        minNeighbors = 5,\n",
    "                                        minSize = (24, 24))\n",
    "        \n",
    "        # Save the faces by appending indices to the filename before saving them\n",
    "        if len(faces) > 0:\n",
    "            for internal_idx, (x, y, w, h) in enumerate(faces, start = 1):\n",
    "                subset = image[x:x + w, y:y + h]\n",
    "                output_fname, output_ext = \".\".join(filename.split(\".\")[:-1]), filename.split(\".\")[-1]\n",
    "                dest_fname = f\"{output_folder}/{output_fname}_{str(internal_idx)}.{output_ext}\"\n",
    "                # print(filename, output_fname, dest_fname)\n",
    "                cv2.imwrite(dest_fname, subset)\n",
    "        else:\n",
    "            pass\n",
    "            # cv2.imwrite(, image)\n",
    "    except Exception as e:\n",
    "        print(str(e), file)\n",
    "\n",
    "# Create a destination directory (if it doesn't already exist)\n",
    "if not os.path.exists(dest_path):\n",
    "    os.mkdir(dest_path)\n",
    "\n",
    "# Get a list of all the source files\n",
    "all_files = []\n",
    "for root, dirs, files in os.walk(src_path):\n",
    "    for file in files:\n",
    "        all_files.append(os.path.join(root, file))\n",
    "\n",
    "# For every source file, apply the face detection lbp cascade and extract \n",
    "# the images in destination directory\n",
    "for file in all_files:\n",
    "\n",
    "    components = file.split(\"/\")\n",
    "    character_name, file_name = components[-2], components[-1]\n",
    "    character_pth = os.path.join(dest_path, character_name)\n",
    "\n",
    "    if not os.path.exists(character_pth):\n",
    "        os.mkdir(character_pth)\n",
    "    \n",
    "    detect(file, character_pth)\n",
    "```\n",
    "\n",
    "To summarise the above code, we are basically reading in the image, converting it to grayscale and then we pass it through the lbp cascade and extract regions of interest i.e. faces; for every image, for every face extracted from that image, we save the image with the same name as the original filename only appending an index to it at the end for the faces generated. for eg. If our source image is Kuroko.jpg and it contains three figures of Kuroko Tetsuya, we save the resulting extractions as Kuroko_1.jpg, Kuroko_2.jpg and Kuroko_3.jpg respectively. \n",
    "\n",
    "## Results\n",
    "\n",
    "Although at a high level, these lbpcascades work fine, they don't work pretty well for our usecase. For eg. let's take the example of Kuroko Tetsuya's image folder. I had initially extracted 50 images for every character and for Kuroko, this is how the snipper looks like.\n",
    "\n",
    "<img src=\"../img/kuroko_all.png\" width=\"80%\" style=\"border: 1px solid black\">\n",
    "\n",
    "When I used nagadomi's face extractor, what I ended up getting is something as follows:\n",
    "\n",
    "<img src=\"../img/kuroko_cropped.png\" width=\"80%\" style=\"border: 1px solid black\">\n",
    "\n",
    "\n",
    "So from the above two pics, we can see that for some images, this technique fetches alright results but for most images, it's not working very well. Such was the case for most of the characters across all the images. So, I took the aid of this cropping method to get facial images but I also went through other images manually to crop the faces of different characters. Despite this, there were a few characters for which, the 32 mark for number of images was not met (Mostly because the scraped data contained images which were figurines, keychains etc. for those characters and not the actual character images).\n",
    "\n",
    "## Balancing datasets\n",
    "\n",
    "After cropping the relevant images, we can see that across different characters, the number of images available are quite different and some characters' images fall short of our pre-decided 32 images mark. \n",
    "\n",
    "In such a case, we can go on and collect more data or simply replicate some images randomly across the available images per character and this can help mitigate the problem as well. \n",
    "\n",
    "```python\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Base path where images are stored\n",
    "base_pth = \"/home/vinayak/cleaned_anime_faces\"\n",
    "N = 32\n",
    "\n",
    "# Loop over every character \n",
    "for character in os.listdir(base_pth):\n",
    "    char_path = os.path.join(base_pth, character)\n",
    "\n",
    "    # See the number of images per character\n",
    "    images = os.listdir(char_path)\n",
    "    deficit = N - len(images)\n",
    "    \n",
    "    # If there's fewer than N images in a character, duplicate the character \n",
    "    # images till the deficit is succesfully accounted for\n",
    "    if deficit > 0:\n",
    "        random_sampled_images = random.sample(images, deficit)\n",
    "\n",
    "        # From the random sampled images, paste them by appending a suffix \n",
    "        # _balancing to hint at the reason of duplication\n",
    "        for img in random_sampled_images:\n",
    "            src = os.path.join(char_path, img)\n",
    "            \n",
    "            img_name, img_ext = img.split(\".\")[0], img.split(\".\")[-1]\n",
    "            modified_img_name = f\"{img_name}_balancing.{img_ext}\"\n",
    "            dest = os.path.join(char_path, modified_img_name)\n",
    "\n",
    "            shutil.copy(src, dest)\n",
    "```\n",
    "\n",
    "We define an N i.e. number of images per class that MUST, AT LEAST be present. Next, we iterate over the characters and for each character find out the deficit number of images if any. In case there exists some deficit of images, we randomly sample those many i.e. deficit number of images from our collected & cropped data and add the suffix `_balancing` to the image name to indicate this image is a duplicate created for the purpose of balancing the dataset.\n",
    "\n",
    "Although this is a naive way of approaching class imbalance, it works wonders as compared to keeping the data imbalanced in the first place. We could also go for some augmentation technique like rotation, flipping, contrast/brightness change etc. to create another new distinct image as well. In this post, I have resorted to simply replicating the images as they are and that has worked alright for me."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-approval",
   "metadata": {},
   "source": [
    "Once we have these steps ready, we can move on to the next step which is actually training a deep learning model to perform the face identification procedure. \n",
    "\n",
    "This is it for now, we shall cover the model training aspect in the subsequent post.\n",
    "\n",
    "\n",
    "# References\n",
    "\n",
    "1. [Github repo with all code for this post](https://github.com/ElisonSherton/anime_face_recognition/tree/master/data_prep)\n",
    "2. [google_images_download library documentation](https://google-images-download.readthedocs.io/en/latest/installation.html)\n",
    "3. [nagadomi's lbpcascade for anime face detection](https://github.com/nagadomi/lbpcascade_animeface)\n",
    "4. [Similarity Learning on wikipedia](https://en.wikipedia.org/wiki/Similarity_learning)\n",
    "5. [More on metric learning](http://contrib.scikit-learn.org/metric-learn/introduction.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
