{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we shall be using Siamese Network in order to build a model to perform the task of face verification for a given character.\n",
    "\n",
    "The paper referred to for performing this experiment is [linked here](https://proceedings.neurips.cc/paper/1993/file/288cc0ff022877bd3df94bc9360b9c5d-Paper.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from siameseDataset import *\n",
    "from loss_func import *\n",
    "from siameseModel import *\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "import pandas as pd\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/vinayak/cleaned_anime_faces\"\n",
    "model_save_path = \"/home/vinayak/anime_face_recognition/resources/enet_model.pth\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = {}\n",
    "split_info = pd.read_csv(f\"/home/vinayak/anime_face_recognition/resources/data.csv\")\n",
    "partition[\"train\"] = list(split_info[split_info.label == \"train\"].images)\n",
    "random.shuffle(partition[\"train\"])\n",
    "partition[\"validation\"] = list(split_info[split_info.label == \"valid\"].images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://omoindrot.github.io/triplet-loss#strategies-in-online-mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training dataset and use it to create a training_generator\n",
    "training_set = siameseDataset(partition['train'])\n",
    "training_generator = torch.utils.data.DataLoader(training_set, batch_size = 1)\n",
    "# training_set.show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training dataset and use it to create a validation_generator\n",
    "validation_set = siameseDataset(partition['validation'], dtype = \"validation\")\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, batch_size = 1)\n",
    "# validation_set.show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and move it to appropriate device (i.e. cuda if gpu is available)\n",
    "model = enet_model().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function to be used for training\n",
    "loss_func = batchHardTripletLoss(margin = 0.2).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a learning rate and create an optimizer for training the model \n",
    "# (Adam with default momentum should be good)\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Define a learning rate scheduler so that you reduce the learning rate\n",
    "# As you progress across multiple epochs\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 3, gamma = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1   \n",
      "Batch Number: 1 | Current Batch Loss: 1.73517| Average Train Loss: 1.73517\n",
      "Batch Number: 30| Current Batch Loss: 0.78829| Average Train Loss: 1.25657\n",
      "Batch Number: 60| Current Batch Loss: 0.6211 | Average Train Loss: 1.01586\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 1  --->  Train Loss: 1.01586  --->  Valid Loss: 0.49077\n",
      "\n",
      "Epoch 2   \n",
      "Batch Number: 1 | Current Batch Loss: 0.39206| Average Train Loss: 0.39206\n",
      "Batch Number: 30| Current Batch Loss: 0.43559| Average Train Loss: 0.45994\n",
      "Batch Number: 60| Current Batch Loss: 0.1999 | Average Train Loss: 0.43082\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 2  --->  Train Loss: 0.43082  --->  Valid Loss: 0.35034\n",
      "\n",
      "Epoch 3   \n",
      "Batch Number: 1 | Current Batch Loss: 0.25044| Average Train Loss: 0.25044\n",
      "Batch Number: 30| Current Batch Loss: 0.39115| Average Train Loss: 0.30122\n",
      "Batch Number: 60| Current Batch Loss: 0.31324| Average Train Loss: 0.26837\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 3  --->  Train Loss: 0.26837  --->  Valid Loss: 0.21012\n",
      "\n",
      "Epoch 4   \n",
      "Batch Number: 1 | Current Batch Loss: 0.3045 | Average Train Loss: 0.3045 \n",
      "Batch Number: 30| Current Batch Loss: 0.13186| Average Train Loss: 0.25451\n",
      "Batch Number: 60| Current Batch Loss: 0.37611| Average Train Loss: 0.2496 \n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 4  --->  Train Loss: 0.2496   --->  Valid Loss: 0.20774\n",
      "\n",
      "Epoch 5   \n",
      "Batch Number: 1 | Current Batch Loss: 0.28034| Average Train Loss: 0.28034\n",
      "Batch Number: 30| Current Batch Loss: 0.0501 | Average Train Loss: 0.17701\n",
      "Batch Number: 60| Current Batch Loss: 0.12834| Average Train Loss: 0.18294\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 5  --->  Train Loss: 0.18294  --->  Valid Loss: 0.20197\n",
      "\n",
      "Epoch 6   \n",
      "Batch Number: 1 | Current Batch Loss: 0.20422| Average Train Loss: 0.20422\n",
      "Batch Number: 30| Current Batch Loss: 0.08905| Average Train Loss: 0.14868\n",
      "Batch Number: 60| Current Batch Loss: 0.0    | Average Train Loss: 0.13954\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 6  --->  Train Loss: 0.13954  --->  Valid Loss: 0.1958 \n",
      "\n",
      "Epoch 7   \n",
      "Batch Number: 1 | Current Batch Loss: 0.05132| Average Train Loss: 0.05132\n",
      "Batch Number: 30| Current Batch Loss: 0.211  | Average Train Loss: 0.17398\n",
      "Batch Number: 60| Current Batch Loss: 0.01878| Average Train Loss: 0.151  \n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 7  --->  Train Loss: 0.151    --->  Valid Loss: 0.14117\n",
      "\n",
      "Epoch 8   \n",
      "Batch Number: 1 | Current Batch Loss: 0.0824 | Average Train Loss: 0.0824 \n",
      "Batch Number: 30| Current Batch Loss: 0.07324| Average Train Loss: 0.14134\n",
      "Batch Number: 60| Current Batch Loss: 0.19013| Average Train Loss: 0.14173\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 8  --->  Train Loss: 0.14173  --->  Valid Loss: 0.17996\n",
      "\n",
      "Epoch 9   \n",
      "Batch Number: 1 | Current Batch Loss: 0.08124| Average Train Loss: 0.08124\n",
      "Batch Number: 30| Current Batch Loss: 0.27934| Average Train Loss: 0.14329\n",
      "Batch Number: 60| Current Batch Loss: 0.17415| Average Train Loss: 0.11565\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 9  --->  Train Loss: 0.11565  --->  Valid Loss: 0.15557\n",
      "\n",
      "Epoch 10  \n",
      "Batch Number: 1 | Current Batch Loss: 0.06889| Average Train Loss: 0.06889\n",
      "Batch Number: 30| Current Batch Loss: 0.04667| Average Train Loss: 0.09722\n",
      "Batch Number: 60| Current Batch Loss: 0.32074| Average Train Loss: 0.1072 \n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 10 --->  Train Loss: 0.1072   --->  Valid Loss: 0.18069\n",
      "\n",
      "Epoch 11  \n",
      "Batch Number: 1 | Current Batch Loss: 0.08845| Average Train Loss: 0.08845\n",
      "Batch Number: 30| Current Batch Loss: 0.11683| Average Train Loss: 0.1003 \n",
      "Batch Number: 60| Current Batch Loss: 0.23984| Average Train Loss: 0.11579\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 11 --->  Train Loss: 0.11579  --->  Valid Loss: 0.15557\n",
      "\n",
      "Epoch 12  \n",
      "Batch Number: 1 | Current Batch Loss: 0.00929| Average Train Loss: 0.00929\n",
      "Batch Number: 30| Current Batch Loss: 0.15108| Average Train Loss: 0.10711\n",
      "Batch Number: 60| Current Batch Loss: 0.01742| Average Train Loss: 0.09544\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 12 --->  Train Loss: 0.09544  --->  Valid Loss: 0.19413\n",
      "\n",
      "Epoch 13  \n",
      "Batch Number: 1 | Current Batch Loss: 0.0    | Average Train Loss: 0.0    \n",
      "Batch Number: 30| Current Batch Loss: 0.16215| Average Train Loss: 0.10799\n",
      "Batch Number: 60| Current Batch Loss: 0.00557| Average Train Loss: 0.09644\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 13 --->  Train Loss: 0.09644  --->  Valid Loss: 0.1945 \n",
      "\n",
      "Epoch 14  \n",
      "Batch Number: 1 | Current Batch Loss: 0.00411| Average Train Loss: 0.00411\n",
      "Batch Number: 30| Current Batch Loss: 0.08508| Average Train Loss: 0.0766 \n",
      "Batch Number: 60| Current Batch Loss: 0.08446| Average Train Loss: 0.08329\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 14 --->  Train Loss: 0.08329  --->  Valid Loss: 0.14672\n",
      "\n",
      "Epoch 15  \n",
      "Batch Number: 1 | Current Batch Loss: 0.0    | Average Train Loss: 0.0    \n",
      "Batch Number: 30| Current Batch Loss: 0.01438| Average Train Loss: 0.07296\n",
      "Batch Number: 60| Current Batch Loss: 0.30747| Average Train Loss: 0.07552\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 15 --->  Train Loss: 0.07552  --->  Valid Loss: 0.16007\n",
      "\n",
      "Epoch 16  \n",
      "Batch Number: 1 | Current Batch Loss: 0.10986| Average Train Loss: 0.10986\n",
      "Batch Number: 30| Current Batch Loss: 0.01409| Average Train Loss: 0.06936\n",
      "Batch Number: 60| Current Batch Loss: 0.02545| Average Train Loss: 0.06377\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 16 --->  Train Loss: 0.06377  --->  Valid Loss: 0.13754\n",
      "\n",
      "Epoch 17  \n",
      "Batch Number: 1 | Current Batch Loss: 0.03258| Average Train Loss: 0.03258\n",
      "Batch Number: 30| Current Batch Loss: 0.0217 | Average Train Loss: 0.08014\n",
      "Batch Number: 60| Current Batch Loss: 0.0    | Average Train Loss: 0.06111\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 17 --->  Train Loss: 0.06111  --->  Valid Loss: 0.18383\n",
      "\n",
      "Epoch 18  \n",
      "Batch Number: 1 | Current Batch Loss: 0.15562| Average Train Loss: 0.15562\n",
      "Batch Number: 30| Current Batch Loss: 0.02507| Average Train Loss: 0.08359\n",
      "Batch Number: 60| Current Batch Loss: 0.0    | Average Train Loss: 0.08477\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 18 --->  Train Loss: 0.08477  --->  Valid Loss: 0.15325\n",
      "\n",
      "Epoch 19  \n",
      "Batch Number: 1 | Current Batch Loss: 0.0    | Average Train Loss: 0.0    \n",
      "Batch Number: 30| Current Batch Loss: 0.07737| Average Train Loss: 0.05278\n",
      "Batch Number: 60| Current Batch Loss: 0.0809 | Average Train Loss: 0.04769\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 19 --->  Train Loss: 0.04769  --->  Valid Loss: 0.17424\n",
      "\n",
      "Epoch 20  \n",
      "Batch Number: 1 | Current Batch Loss: 0.13622| Average Train Loss: 0.13622\n",
      "Batch Number: 30| Current Batch Loss: 0.17921| Average Train Loss: 0.04248\n",
      "Batch Number: 60| Current Batch Loss: 0.0    | Average Train Loss: 0.04299\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 20 --->  Train Loss: 0.04299  --->  Valid Loss: 0.15142\n",
      "\n",
      "Epoch 21  \n",
      "Batch Number: 1 | Current Batch Loss: 0.00081| Average Train Loss: 0.00081\n",
      "Batch Number: 30| Current Batch Loss: 0.26139| Average Train Loss: 0.0582 \n",
      "Batch Number: 60| Current Batch Loss: 0.0406 | Average Train Loss: 0.04971\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 21 --->  Train Loss: 0.04971  --->  Valid Loss: 0.17396\n",
      "\n",
      "Epoch 22  \n",
      "Batch Number: 1 | Current Batch Loss: 0.00112| Average Train Loss: 0.00112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number: 30| Current Batch Loss: 0.0    | Average Train Loss: 0.05054\n",
      "Batch Number: 60| Current Batch Loss: 0.04469| Average Train Loss: 0.04775\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 22 --->  Train Loss: 0.04775  --->  Valid Loss: 0.12835\n",
      "\n",
      "Epoch 23  \n",
      "Batch Number: 1 | Current Batch Loss: 0.01458| Average Train Loss: 0.01458\n",
      "Batch Number: 30| Current Batch Loss: 0.0    | Average Train Loss: 0.05446\n",
      "Batch Number: 60| Current Batch Loss: 0.0    | Average Train Loss: 0.03851\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 23 --->  Train Loss: 0.03851  --->  Valid Loss: 0.10711\n",
      "\n",
      "Epoch 24  \n",
      "Batch Number: 1 | Current Batch Loss: 0.0    | Average Train Loss: 0.0    \n",
      "Batch Number: 30| Current Batch Loss: 0.0    | Average Train Loss: 0.0424 \n",
      "Batch Number: 60| Current Batch Loss: 0.08148| Average Train Loss: 0.04298\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 24 --->  Train Loss: 0.04298  --->  Valid Loss: 0.17469\n",
      "\n",
      "Epoch 25  \n",
      "Batch Number: 1 | Current Batch Loss: 0.06391| Average Train Loss: 0.06391\n",
      "Batch Number: 30| Current Batch Loss: 0.22014| Average Train Loss: 0.0492 \n",
      "Batch Number: 60| Current Batch Loss: 0.1999 | Average Train Loss: 0.04457\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 25 --->  Train Loss: 0.04457  --->  Valid Loss: 0.13948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "n_epochs = 25\n",
    "n_train_batches = len(training_generator)\n",
    "n_valid_batches = len(validation_generator)\n",
    "PRINT_PROGRESS = 30\n",
    "\n",
    "round_off = lambda x: round(x, 5)\n",
    "\n",
    "# Loop over number of epochs\n",
    "for epch in range(n_epochs):\n",
    "    \n",
    "    print(f\"Epoch {(epch + 1):<4}\")\n",
    "    # Initialize the loss values to zero at the beginning of the epoch\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "\n",
    "    # Train for an epoch\n",
    "    for idx, (images, labels) in enumerate(training_generator, start = 1):\n",
    "        images, labels = images[0].to(DEVICE), labels.to(DEVICE)\n",
    "        feature_vectors = model(images)\n",
    "        loss = loss_func(feature_vectors, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = round_off(loss.item())\n",
    "        train_loss += batch_loss\n",
    "        \n",
    "        if (idx % PRINT_PROGRESS == 0) or (idx == 1) or (idx == n_train_batches):\n",
    "            print(f\"Batch Number: {idx:<2}| Current Batch Loss: {batch_loss:<7}| Average Train Loss: {round_off(train_loss / idx):<7}\")\n",
    "    \n",
    "    # Validate after the trained epoch\n",
    "    for images, labels in validation_generator:\n",
    "        images, labels = images[0].to(DEVICE), labels.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            feature_vectors = model(images)\n",
    "            loss = loss_func(feature_vectors, labels)\n",
    "            valid_loss += round_off(loss.item())\n",
    "    \n",
    "    # Reset the states of training and validation sets\n",
    "    validation_set.characters_selected = {k:0 for k in validation_set.classes}\n",
    "    validation_set.images_selected = {k:False for k in validation_set.images}\n",
    "    \n",
    "    training_set.characters_selected = {k:0 for k in training_set.classes}\n",
    "    training_set.images_selected = {k:False for k in training_set.images}\n",
    "    \n",
    "    # Average the train and valid losses across all batches and save it to our array\n",
    "    train_loss = round_off(train_loss / n_train_batches)\n",
    "    valid_loss = round_off(valid_loss / n_valid_batches)\n",
    "    \n",
    "    print(\"\".join([\"-\"]*75))\n",
    "    print(f\"Summary for Epoch {(epch + 1):<2} --->  Train Loss: {train_loss:<7}  --->  Valid Loss: {valid_loss:<7}\")\n",
    "    print()\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    # Check the valid loss and reduce learning rate as per the need\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the losses to a loss_history.csv file on the disk\n",
    "history = pd.DataFrame({\"train_loss\": train_losses, \"valid_loss\":valid_losses})\n",
    "history.to_csv(\"loss_history.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curve obtained when training\n",
    "ax = history.plot();\n",
    "ax.set_xlabel(\"Epoch Number\")\n",
    "ax.set_ylabel(\"Batch Hard Triplet Loss\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to our disk\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_size': 3,\n",
       " 'gamma': 0.8,\n",
       " 'base_lrs': [0.0001],\n",
       " 'last_epoch': 25,\n",
       " '_step_count': 26,\n",
       " '_get_lr_called_within_step': False,\n",
       " '_last_lr': [1.677721600000001e-05]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the progresion of learning rates\n",
    "scheduler.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
