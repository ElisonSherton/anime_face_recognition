{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we shall be using Siamese Network in order to build a model to perform the task of face verification for a given character.\n",
    "\n",
    "The paper referred to for performing this experiment is [linked here](https://proceedings.neurips.cc/paper/1993/file/288cc0ff022877bd3df94bc9360b9c5d-Paper.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from siameseDataset import *\n",
    "from loss_func import *\n",
    "from siameseModel import *\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "import pandas as pd\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/vinayak/cleaned_anime_faces\"\n",
    "model_save_path = \"/home/vinayak/anime_face_recognition/enet_model.pth\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = {}\n",
    "split_info = pd.read_csv(f\"/home/vinayak/anime_face_recognition/data.csv\")\n",
    "partition[\"train\"] = list(split_info[split_info.label == \"train\"].images)\n",
    "random.shuffle(partition[\"train\"])\n",
    "partition[\"validation\"] = list(split_info[split_info.label == \"valid\"].images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://omoindrot.github.io/triplet-loss#strategies-in-online-mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training dataset and use it to create a training_generator\n",
    "training_set = siameseDataset(partition['train'])\n",
    "training_generator = torch.utils.data.DataLoader(training_set, batch_size = 1)\n",
    "# training_set.show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training dataset and use it to create a validation_generator\n",
    "validation_set = siameseDataset(partition['validation'], dtype = \"validation\")\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, batch_size = 1)\n",
    "# validation_set.show_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and move it to appropriate device (i.e. cuda if gpu is available)\n",
    "model = enet_model().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function to be used for training\n",
    "loss_func = batchHardTripletLoss(margin = 0.2).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a learning rate and create an optimizer for training the model \n",
    "# (Adam with default momentum should be good)\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Define a learning rate scheduler so that you reduce the learning rate\n",
    "# As you progress across multiple epochs\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 3, gamma = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1   \n",
      "Batch Number: 1 | Current Batch Loss: 1.73517| Average Train Loss: 1.73517\n",
      "Batch Number: 30| Current Batch Loss: 0.78829| Average Train Loss: 1.25657\n",
      "Batch Number: 60| Current Batch Loss: 0.6211 | Average Train Loss: 1.01586\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 1  --->  Train Loss: 1.01586  --->  Valid Loss: 0.49077\n",
      "\n",
      "Epoch 2   \n",
      "Batch Number: 1 | Current Batch Loss: 0.39206| Average Train Loss: 0.39206\n",
      "Batch Number: 30| Current Batch Loss: 0.43559| Average Train Loss: 0.45994\n",
      "Batch Number: 60| Current Batch Loss: 0.1999 | Average Train Loss: 0.43082\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 2  --->  Train Loss: 0.43082  --->  Valid Loss: 0.35034\n",
      "\n",
      "Epoch 3   \n",
      "Batch Number: 1 | Current Batch Loss: 0.25044| Average Train Loss: 0.25044\n",
      "Batch Number: 30| Current Batch Loss: 0.39115| Average Train Loss: 0.30122\n",
      "Batch Number: 60| Current Batch Loss: 0.31324| Average Train Loss: 0.26837\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 3  --->  Train Loss: 0.26837  --->  Valid Loss: 0.21012\n",
      "\n",
      "Epoch 4   \n",
      "Batch Number: 1 | Current Batch Loss: 0.3045 | Average Train Loss: 0.3045 \n",
      "Batch Number: 30| Current Batch Loss: 0.13186| Average Train Loss: 0.25451\n",
      "Batch Number: 60| Current Batch Loss: 0.37611| Average Train Loss: 0.2496 \n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 4  --->  Train Loss: 0.2496   --->  Valid Loss: 0.20774\n",
      "\n",
      "Epoch 5   \n",
      "Batch Number: 1 | Current Batch Loss: 0.28034| Average Train Loss: 0.28034\n",
      "Batch Number: 30| Current Batch Loss: 0.0501 | Average Train Loss: 0.17701\n",
      "Batch Number: 60| Current Batch Loss: 0.12834| Average Train Loss: 0.18294\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 5  --->  Train Loss: 0.18294  --->  Valid Loss: 0.20197\n",
      "\n",
      "Epoch 6   \n",
      "Batch Number: 1 | Current Batch Loss: 0.20422| Average Train Loss: 0.20422\n",
      "Batch Number: 30| Current Batch Loss: 0.08905| Average Train Loss: 0.14868\n",
      "Batch Number: 60| Current Batch Loss: 0.0    | Average Train Loss: 0.13954\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 6  --->  Train Loss: 0.13954  --->  Valid Loss: 0.1958 \n",
      "\n",
      "Epoch 7   \n",
      "Batch Number: 1 | Current Batch Loss: 0.05132| Average Train Loss: 0.05132\n",
      "Batch Number: 30| Current Batch Loss: 0.211  | Average Train Loss: 0.17398\n",
      "Batch Number: 60| Current Batch Loss: 0.01878| Average Train Loss: 0.151  \n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 7  --->  Train Loss: 0.151    --->  Valid Loss: 0.14117\n",
      "\n",
      "Epoch 8   \n",
      "Batch Number: 1 | Current Batch Loss: 0.0824 | Average Train Loss: 0.0824 \n",
      "Batch Number: 30| Current Batch Loss: 0.07324| Average Train Loss: 0.14134\n",
      "Batch Number: 60| Current Batch Loss: 0.19013| Average Train Loss: 0.14173\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 8  --->  Train Loss: 0.14173  --->  Valid Loss: 0.17996\n",
      "\n",
      "Epoch 9   \n",
      "Batch Number: 1 | Current Batch Loss: 0.08124| Average Train Loss: 0.08124\n",
      "Batch Number: 30| Current Batch Loss: 0.27934| Average Train Loss: 0.14329\n",
      "Batch Number: 60| Current Batch Loss: 0.17415| Average Train Loss: 0.11565\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 9  --->  Train Loss: 0.11565  --->  Valid Loss: 0.15557\n",
      "\n",
      "Epoch 10  \n",
      "Batch Number: 1 | Current Batch Loss: 0.06889| Average Train Loss: 0.06889\n",
      "Batch Number: 30| Current Batch Loss: 0.04667| Average Train Loss: 0.09722\n",
      "Batch Number: 60| Current Batch Loss: 0.32074| Average Train Loss: 0.1072 \n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 10 --->  Train Loss: 0.1072   --->  Valid Loss: 0.18069\n",
      "\n",
      "Epoch 11  \n",
      "Batch Number: 1 | Current Batch Loss: 0.08845| Average Train Loss: 0.08845\n",
      "Batch Number: 30| Current Batch Loss: 0.11683| Average Train Loss: 0.1003 \n",
      "Batch Number: 60| Current Batch Loss: 0.23984| Average Train Loss: 0.11579\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 11 --->  Train Loss: 0.11579  --->  Valid Loss: 0.15557\n",
      "\n",
      "Epoch 12  \n",
      "Batch Number: 1 | Current Batch Loss: 0.00929| Average Train Loss: 0.00929\n",
      "Batch Number: 30| Current Batch Loss: 0.15108| Average Train Loss: 0.10711\n",
      "Batch Number: 60| Current Batch Loss: 0.01742| Average Train Loss: 0.09544\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 12 --->  Train Loss: 0.09544  --->  Valid Loss: 0.19413\n",
      "\n",
      "Epoch 13  \n",
      "Batch Number: 1 | Current Batch Loss: 0.0    | Average Train Loss: 0.0    \n",
      "Batch Number: 30| Current Batch Loss: 0.16215| Average Train Loss: 0.10799\n",
      "Batch Number: 60| Current Batch Loss: 0.00557| Average Train Loss: 0.09644\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 13 --->  Train Loss: 0.09644  --->  Valid Loss: 0.1945 \n",
      "\n",
      "Epoch 14  \n",
      "Batch Number: 1 | Current Batch Loss: 0.00411| Average Train Loss: 0.00411\n",
      "Batch Number: 30| Current Batch Loss: 0.08508| Average Train Loss: 0.0766 \n",
      "Batch Number: 60| Current Batch Loss: 0.08446| Average Train Loss: 0.08329\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 14 --->  Train Loss: 0.08329  --->  Valid Loss: 0.14672\n",
      "\n",
      "Epoch 15  \n",
      "Batch Number: 1 | Current Batch Loss: 0.0    | Average Train Loss: 0.0    \n",
      "Batch Number: 30| Current Batch Loss: 0.01438| Average Train Loss: 0.07296\n",
      "Batch Number: 60| Current Batch Loss: 0.30747| Average Train Loss: 0.07552\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 15 --->  Train Loss: 0.07552  --->  Valid Loss: 0.16007\n",
      "\n",
      "Epoch 16  \n",
      "Batch Number: 1 | Current Batch Loss: 0.10986| Average Train Loss: 0.10986\n",
      "Batch Number: 30| Current Batch Loss: 0.01409| Average Train Loss: 0.06936\n",
      "Batch Number: 60| Current Batch Loss: 0.02545| Average Train Loss: 0.06377\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 16 --->  Train Loss: 0.06377  --->  Valid Loss: 0.13754\n",
      "\n",
      "Epoch 17  \n",
      "Batch Number: 1 | Current Batch Loss: 0.03258| Average Train Loss: 0.03258\n",
      "Batch Number: 30| Current Batch Loss: 0.0217 | Average Train Loss: 0.08014\n",
      "Batch Number: 60| Current Batch Loss: 0.0    | Average Train Loss: 0.06111\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 17 --->  Train Loss: 0.06111  --->  Valid Loss: 0.18383\n",
      "\n",
      "Epoch 18  \n",
      "Batch Number: 1 | Current Batch Loss: 0.15562| Average Train Loss: 0.15562\n",
      "Batch Number: 30| Current Batch Loss: 0.02507| Average Train Loss: 0.08359\n",
      "Batch Number: 60| Current Batch Loss: 0.0    | Average Train Loss: 0.08477\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 18 --->  Train Loss: 0.08477  --->  Valid Loss: 0.15325\n",
      "\n",
      "Epoch 19  \n",
      "Batch Number: 1 | Current Batch Loss: 0.0    | Average Train Loss: 0.0    \n",
      "Batch Number: 30| Current Batch Loss: 0.07737| Average Train Loss: 0.05278\n",
      "Batch Number: 60| Current Batch Loss: 0.0809 | Average Train Loss: 0.04769\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 19 --->  Train Loss: 0.04769  --->  Valid Loss: 0.17424\n",
      "\n",
      "Epoch 20  \n",
      "Batch Number: 1 | Current Batch Loss: 0.13622| Average Train Loss: 0.13622\n",
      "Batch Number: 30| Current Batch Loss: 0.17921| Average Train Loss: 0.04248\n",
      "Batch Number: 60| Current Batch Loss: 0.0    | Average Train Loss: 0.04299\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 20 --->  Train Loss: 0.04299  --->  Valid Loss: 0.15142\n",
      "\n",
      "Epoch 21  \n",
      "Batch Number: 1 | Current Batch Loss: 0.00081| Average Train Loss: 0.00081\n",
      "Batch Number: 30| Current Batch Loss: 0.26139| Average Train Loss: 0.0582 \n",
      "Batch Number: 60| Current Batch Loss: 0.0406 | Average Train Loss: 0.04971\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 21 --->  Train Loss: 0.04971  --->  Valid Loss: 0.17396\n",
      "\n",
      "Epoch 22  \n",
      "Batch Number: 1 | Current Batch Loss: 0.00112| Average Train Loss: 0.00112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Number: 30| Current Batch Loss: 0.0    | Average Train Loss: 0.05054\n",
      "Batch Number: 60| Current Batch Loss: 0.04469| Average Train Loss: 0.04775\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 22 --->  Train Loss: 0.04775  --->  Valid Loss: 0.12835\n",
      "\n",
      "Epoch 23  \n",
      "Batch Number: 1 | Current Batch Loss: 0.01458| Average Train Loss: 0.01458\n",
      "Batch Number: 30| Current Batch Loss: 0.0    | Average Train Loss: 0.05446\n",
      "Batch Number: 60| Current Batch Loss: 0.0    | Average Train Loss: 0.03851\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 23 --->  Train Loss: 0.03851  --->  Valid Loss: 0.10711\n",
      "\n",
      "Epoch 24  \n",
      "Batch Number: 1 | Current Batch Loss: 0.0    | Average Train Loss: 0.0    \n",
      "Batch Number: 30| Current Batch Loss: 0.0    | Average Train Loss: 0.0424 \n",
      "Batch Number: 60| Current Batch Loss: 0.08148| Average Train Loss: 0.04298\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 24 --->  Train Loss: 0.04298  --->  Valid Loss: 0.17469\n",
      "\n",
      "Epoch 25  \n",
      "Batch Number: 1 | Current Batch Loss: 0.06391| Average Train Loss: 0.06391\n",
      "Batch Number: 30| Current Batch Loss: 0.22014| Average Train Loss: 0.0492 \n",
      "Batch Number: 60| Current Batch Loss: 0.1999 | Average Train Loss: 0.04457\n",
      "---------------------------------------------------------------------------\n",
      "Summary for Epoch 25 --->  Train Loss: 0.04457  --->  Valid Loss: 0.13948\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "n_epochs = 25\n",
    "n_train_batches = len(training_generator)\n",
    "n_valid_batches = len(validation_generator)\n",
    "PRINT_PROGRESS = 30\n",
    "\n",
    "round_off = lambda x: round(x, 5)\n",
    "\n",
    "# Loop over number of epochs\n",
    "for epch in range(n_epochs):\n",
    "    \n",
    "    print(f\"Epoch {(epch + 1):<4}\")\n",
    "    # Initialize the loss values to zero at the beginning of the epoch\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "\n",
    "    # Train for an epoch\n",
    "    for idx, (images, labels) in enumerate(training_generator, start = 1):\n",
    "        images, labels = images[0].to(DEVICE), labels.to(DEVICE)\n",
    "        feature_vectors = model(images)\n",
    "        loss = loss_func(feature_vectors, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = round_off(loss.item())\n",
    "        train_loss += batch_loss\n",
    "        \n",
    "        if (idx % PRINT_PROGRESS == 0) or (idx == 1) or (idx == n_train_batches):\n",
    "            print(f\"Batch Number: {idx:<2}| Current Batch Loss: {batch_loss:<7}| Average Train Loss: {round_off(train_loss / idx):<7}\")\n",
    "    \n",
    "    # Validate after the trained epoch\n",
    "    for images, labels in validation_generator:\n",
    "        images, labels = images[0].to(DEVICE), labels.to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            feature_vectors = model(images)\n",
    "            loss = loss_func(feature_vectors, labels)\n",
    "            valid_loss += round_off(loss.item())\n",
    "    \n",
    "    # Reset the states of training and validation sets\n",
    "    validation_set.characters_selected = {k:0 for k in validation_set.classes}\n",
    "    validation_set.images_selected = {k:False for k in validation_set.images}\n",
    "    \n",
    "    training_set.characters_selected = {k:0 for k in training_set.classes}\n",
    "    training_set.images_selected = {k:False for k in training_set.images}\n",
    "    \n",
    "    # Average the train and valid losses across all batches and save it to our array\n",
    "    train_loss = round_off(train_loss / n_train_batches)\n",
    "    valid_loss = round_off(valid_loss / n_valid_batches)\n",
    "    \n",
    "    print(\"\".join([\"-\"]*75))\n",
    "    print(f\"Summary for Epoch {(epch + 1):<2} --->  Train Loss: {train_loss:<7}  --->  Valid Loss: {valid_loss:<7}\")\n",
    "    print()\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    # Check the valid loss and reduce learning rate as per the need\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the losses to a loss_history.csv file on the disk\n",
    "history = pd.DataFrame({\"train_loss\": train_losses, \"valid_loss\":valid_losses})\n",
    "history.to_csv(\"loss_history.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to our disk\n",
    "torch.save(model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'step_size': 3,\n",
       " 'gamma': 0.8,\n",
       " 'base_lrs': [0.0001],\n",
       " 'last_epoch': 25,\n",
       " '_step_count': 26,\n",
       " '_get_lr_called_within_step': False,\n",
       " '_last_lr': [1.677721600000001e-05]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scheduler.state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
